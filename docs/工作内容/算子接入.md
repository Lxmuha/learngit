**算子接入工作存在两条线：一是从框架建设本身出发，需要保证功能性和通用性，以相对“标准化”的形式将框架前端算子和加速库高性能实现对接起来；二是从性能优化角度看，尤其是MLPerf任务，需要走定制化的方式支持计算需求大的算子。前期的重点是标准库的接入（如DNN和BLAS），随着此项工作逐渐收敛，目前需要从性能角度review一下MLPerf典型模型的算子支持情况。**

#### 框架API和加速库算子之间潜在的优化空间

1. torch.nn/ATen中的算子和swdnn/swblas提供的kernel在语义上有所差别

* `addbmm addcmul等；
* **对于这类算子，基于dnn/blas可以实现功能，但是仍有优化空间，如广播支持、element-wise计算融合等，可以考虑将其下沉到算子库；**

2. MultiheadAtten`等

* **需要** torch-swai提供接口，改写应用实现；

3. **CPU / CUDA不同的处理方式，如** dropout中的 bernoulli_(待确定)

* **此类算子需要在模型角度分析，明确算子需求；**

4. **Optimizer Half相关计算(FP16)**

* **需分析是否有支**持混合精度 weight(fp32) + grad(fp16)更新的需求；
* ![](https://cdn.nlark.com/yuque/0/2022/png/21688930/1653899287994-c5908052-2e83-4218-b37e-469e563d0e14.png)

5. **其它请**[@Wayne](https://taichu-platform.yuque.com/wayne-dqcxm)补充

#### 任务

* [ ] 以MLPerf中涉及的算子为目标，分析各个算子的支持情况，形成支持计划和 ***算子库需求*** [@孙瑞鑫](https://taichu-platform.yuque.com/ruixinsun)
  * **MLPerf模型中的ATen算子分析：**[https://taichu-platform.yuque.com/mvzg99/yoer36/sf6v1g](https://taichu-platform.yuque.com/mvzg99/yoer36/sf6v1g)
  * **其它：**[https://taichu-platform.yuque.com/xy3e23/lq7a6a/lf3dua](https://taichu-platform.yuque.com/xy3e23/lq7a6a/lf3dua)（重点为3和4）
